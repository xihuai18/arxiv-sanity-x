# arxiv-sanity-X

[‰∏≠Êñá](README_CN.md) | [English](README.md)

A comprehensive arXiv paper browsing and recommendation system featuring AI-powered summarization, hybrid search capabilities, and personalized recommendations. Built with modern ML techniques including TF-IDF, semantic embeddings, and LLM integration.

![Screenshot](arxiv-sanity-x.png)

## üìã Table of Contents

- [Core Overview](#-core-overview)
- [User Guide (Web UI)](#-user-guide-web-ui)
- [Minimum Required to Run](#-minimum-required-to-run)
- [Data Layout & Migration](#-data-layout--migration)
- [Deployment & Security Notes](#-deployment--security-notes)
- [Troubleshooting](#-troubleshooting)
- [Quick Start](#-quick-start)
- [Prerequisites & OS Notes](#-prerequisites--os-notes)
- [Configuration Guide](#configuration-guide)
  - [Configuration Overview](#configuration-overview)
  - [1. vars.py - Core Configuration](#1-varspy---core-configuration)
  - [2. arxiv_daemon.py - arXiv Categories](#2-arxiv_daemonpy---arxiv-categories)
  - [3. llm.yml - LiteLLM Gateway](#3-llmyml---litellm-gateway)
  - [4. Environment Variables](#4-environment-variables)
  - [5. Startup Parameters](#5-startup-parameters)
- [Core Features](#-core-features)
- [Usage Guide](#-usage-guide)
- [AI Paper Summarization](#-ai-paper-summarization)
- [Advanced Features](#-advanced-features)
- [API Reference](#-api-reference)
- [Changelog](#-changelog)

---

## üéØ Core Overview

arxiv-sanity-X is a personal research workbench for tracking arXiv papers. It combines (1) reliable paper ingestion, (2) fast search, and (3) feedback-driven recommendations, so you can quickly find what matters, save it, and keep up daily.

Key capabilities:

- **Paper ingestion & indexing**: fetch papers from selected arXiv categories and maintain a local SQLite-backed database.
- **Multiple search modes**: keyword (TF‚ÄëIDF), semantic (embeddings), and hybrid search with tunable weights.
- **Personal organization**: tags (including negative feedback), combined tags, keywords tracking, and a reading list.
- **AI summaries on demand**: generate structured summaries from HTML (ar5iv/arxiv) or PDF parsing (MinerU), with caching and status tracking.
- **Automation**: optional scheduler for fetch ‚Üí compute ‚Üí summarize ‚Üí email, plus utilities for lock cleanup and data backup.

## üß≠ User Guide (Web UI)

This section is a quick ‚Äúhow to use the website‚Äù map. Most workflows start from the homepage.

### 1) Sign in

- Go to Profile and log in with a username (no password).
- If you plan to expose the site publicly, put it behind authentication/VPN and set a stable `ARXIV_SANITY_SECRET_KEY` (or `secret_key.txt`).

### 2) Search and filter papers

- Homepage search supports field filters like `ti:`, `au:`, `cat:`, and `id:`.
- Switch search mode:
  - **keyword**: fast, no extra services required
  - **semantic**: needs embeddings
  - **hybrid**: best default if embeddings are enabled (adjust weight)

### 3) Tag papers and get recommendations

- Add tags to papers you like to train tag-based recommendations.
- Use negative feedback (when enabled in UI) to down-rank unwanted topics.
- Use combined tags (e.g. ‚ÄúRL,NLP‚Äù) for intersection recommendations.

### 4) Read summaries (on demand)

- Open a paper and click Summary.
- The site generates summaries via your configured LLM and caches results.
- You can clear the current model‚Äôs summary or clear all cached artifacts for a paper.

### 5) Reading list

- Add papers to your reading list for later.
- Useful when you want to queue papers before running batch summarization.

### 6) Optional: email recommendations

- Configure SMTP in [vars.py](vars.py), set `YOUR_EMAIL_PASSWD`, and set a correct public `HOST`.
- Add your email in Profile.
- Run [send_emails.py](send_emails.py) or enable the scheduler daemon ([daemon.py](daemon.py)).

## ‚úÖ Minimum Required to Run

If you want the smallest setup that still works end-to-end (browse + search + on-demand summaries), you need:

1. Create [vars.py](vars.py) from [vars_template.py](vars_template.py).
2. Provide a working LLM API key (commonly via `YOUR_LLM_API_KEY`) and set a valid `LLM_BASE_URL` + `LLM_NAME`.
3. Fetch papers and compute features at least once:

- Run [arxiv_daemon.py](arxiv_daemon.py).
- Run [compute.py](compute.py).

4. Start the web app with [serve.py](serve.py) (or use [run_services.py](run_services.py) if your OS supports bash scripts).

Everything else (embeddings, MinerU, LiteLLM, emails, scheduler) is optional.

## üì¶ Data Layout & Migration

By default, data is stored under `data/` (configured by `DATA_DIR` in [vars.py](vars.py)):

- `data/papers.db`: fetched papers + metadata
- `data/dict.db`: user data (tags, negative tags, keywords, reading list, email registry, summary status)
- `data/features.p`: TF‚ÄëIDF / hybrid features generated by [compute.py](compute.py)
- `data/summary/`: cached LLM summaries
- `data/pdfs/`, `data/mineru/`, `data/html_md/`: intermediate caches for parsing

To migrate to a new machine, you typically copy at least:

- `data/papers.db`
- `data/dict.db`
- `data/features.p` (or regenerate it by running [compute.py](compute.py))
- `data/summary/` (optional, if you want to keep cached summaries)

## üîê Deployment & Security Notes

- The built-in login is **username only** (no password). This is intended for personal / trusted environments.
- If you deploy on a public server, protect it behind authentication/VPN/reverse-proxy, and set a stable secret key via `ARXIV_SANITY_SECRET_KEY` or `secret_key.txt`.
- Do not commit your API keys. Prefer environment variables over editing keys into [vars.py](vars.py).

## üß© Troubleshooting

- **The website is empty / no papers**: you likely didn‚Äôt run [arxiv_daemon.py](arxiv_daemon.py) + [compute.py](compute.py) yet.
- **Summaries always fail**: check `YOUR_LLM_API_KEY`, `LLM_BASE_URL`, `LLM_NAME` in [vars.py](vars.py).
- **Semantic/hybrid search has no effect**: ensure embeddings are enabled and you regenerated features with [compute.py](compute.py) (for hybrid features).
- **MinerU errors**:
  - API backend: check `MINERU_API_KEY` (or `ARXIV_SANITY_MINERU_API_KEY`)
  - local backend: check `ARXIV_SANITY_MINERU_BACKEND` and that the service is reachable on `MINERU_PORT`
- **Stuck jobs after crash (locks)**: run [cleanup_locks.py](cleanup_locks.py) or tune `ARXIV_SANITY_SUMMARY_LOCK_STALE_SEC` / `ARXIV_SANITY_MINERU_LOCK_STALE_SEC`.
- **Cannot load features.p due to NumPy mismatch**: regenerate features by rerunning [compute.py](compute.py) under the current environment.

## ‚ö° Quick Start

This project is ‚Äúbatteries included‚Äù for the web app, but it relies on **external model services** (LLM / embedding / MinerU) that you must choose and configure.

### Recommended Setup Profiles

Pick one profile first, then follow the steps below.

| Profile | What you get | Requires | Recommended for |
| --- | --- | --- | --- |
| **Minimal (LLM-only)** | Browse, search (TF‚ÄëIDF), LLM summaries | LLM API key | First-time users / low resource |
| **Hybrid Search** | TF‚ÄëIDF + embeddings hybrid search | LLM API key + embedding backend | Better relevance |
| **Full (MinerU)** | Strong PDF-to-Markdown parsing (tables/formulas) | MinerU backend (API or local) | Best summary fidelity |

### 1. Installation

```bash
# Clone and install
git clone https://github.com/xihuai18/arxiv-sanity-x && cd arxiv-sanity-x
pip install -r requirements.txt
```

### 2. Create Configuration Files

```bash
# Required: Create vars.py from template
cp vars_template.py vars.py

# Optional: Create LiteLLM config (if using multi-model gateway)
cp llm_template.yml llm.yml
```

### 3. Configure Essential Settings

Edit `vars.py` with your settings (created from [vars_template.py](vars_template.py)).

At minimum, you should review **paths**, **ports**, **LLM**, and (optionally) **summary source / embedding / MinerU**:

```python
# Storage
DATA_DIR = "data"  # Put this on SSD if possible

# LLM API (Required for paper summaries)
LLM_BASE_URL = "https://openrouter.ai/api/v1"  # Or your LLM provider
LLM_API_KEY = os.environ.get("YOUR_LLM_API_KEY", "your_api_key")
LLM_NAME = "deepseek/deepseek-chat-v3.1:free"

# Web
SERVE_PORT = 55555

# Summary source (HTML is fast & default)
SUMMARY_MARKDOWN_SOURCE = os.environ.get("ARXIV_SANITY_SUMMARY_SOURCE", "html")  # html/mineru
SUMMARY_HTML_SOURCES = os.environ.get("ARXIV_SANITY_HTML_SOURCES", "ar5iv,arxiv")

# Email (Optional, for daily recommendations)
from_email = "your_email@mail.com"
smtp_server = "smtp.mail.com"
smtp_port = 465
email_username = "username"
email_passwd = os.environ.get("YOUR_EMAIL_PASSWD", "")
HOST = "http://your-server:55555"  # Public URL for email links

# Embeddings (Optional)
# - If you do NOT run local Ollama, keep EMBED_USE_LLM_API=True (default in template)
# - If you want local Ollama embeddings, set EMBED_USE_LLM_API=False and start Ollama on EMBED_PORT
# EMBED_USE_LLM_API = True
# EMBED_MODEL_NAME = "qwen3-embedding:0.6b"

# MinerU (Optional)
# - api: uses mineru.net (needs MINERU_API_KEY)
# - vlm-http-client: uses local mineru-vllm-server on MINERU_PORT
# - pipeline: run local pipeline inside Python (heavier)
# MINERU_ENABLED = True
# MINERU_BACKEND = "api"
```

Also check the arXiv categories you want to index in [arxiv_daemon.py](arxiv_daemon.py) (`CORE/LANG/AGENT/APP/ALL_TAGS`).

### 4. Set Environment Variables

```bash
# Required
export YOUR_LLM_API_KEY="your-llm-api-key"

# Optional
export MINERU_API_KEY="your-mineru-api-key"     # For MinerU API backend (pdf parsing)
# Alternative alias used by run_services.py (takes precedence over vars.py):
# export ARXIV_SANITY_MINERU_API_KEY="your-mineru-api-key"
export YOUR_EMAIL_PASSWD="your-email-password"  # For email recommendations
export ARXIV_SANITY_SECRET_KEY="$(python3 -c 'import secrets; print(secrets.token_urlsafe(16))')"

# Optional - proxy for arXiv fetch (and other outbound HTTP clients)
# export http_proxy="http://127.0.0.1:7890"
# export https_proxy="http://127.0.0.1:7890"
```

### 5. Fetch Papers and Start

```bash
# Fetch papers and compute features
python3 arxiv_daemon.py -n 10000 -m 500
python3 compute.py --num 20000

# Start all services (one command)
python3 run_services.py

# Visit http://localhost:55555
```

If you need the full stack (embedding / minerU / litellm) in one terminal, use [run_services.py](run_services.py). Note that it calls bash scripts (see OS notes below).

### Configuration Checklist

| Item | File/Location | Required | Description |
| --- | --- | --- | --- |
| **Core Config** | [vars.py](vars.py) | ‚úÖ Yes | `DATA_DIR`, `SERVE_PORT`, LLM + optional email/MinerU/embedding |
| **LLM Provider** | [vars.py](vars.py) + env | ‚úÖ Yes | `LLM_BASE_URL`, `LLM_NAME`, and a working key (`YOUR_LLM_API_KEY` or direct `LLM_API_KEY`) |
| **arXiv Categories** | [arxiv_daemon.py](arxiv_daemon.py) | ‚öôÔ∏è Important | `CORE/LANG/AGENT/APP/ALL_TAGS` controls what you fetch & show |
| **Summary Source** | env or [vars.py](vars.py) | ‚öôÔ∏è Recommended | `ARXIV_SANITY_SUMMARY_SOURCE=html\|mineru`, `ARXIV_SANITY_HTML_SOURCES=ar5iv,arxiv` |
| **Embedding Backend** | env or [vars.py](vars.py) | ‚öôÔ∏è Optional | `ARXIV_SANITY_EMBED_USE_LLM_API` + `EMBED_*` (API) or local Ollama on `EMBED_PORT` |
| **MinerU Backend** | env or [vars.py](vars.py) | ‚öôÔ∏è Optional | `ARXIV_SANITY_MINERU_BACKEND=api\|vlm-http-client\|pipeline` + keys/ports |
| **Email SMTP** | [vars.py](vars.py) + env | ‚öôÔ∏è Optional | SMTP settings + `HOST` + `YOUR_EMAIL_PASSWD` |
| **Session Secret** | env/file | ‚öôÔ∏è Recommended | `ARXIV_SANITY_SECRET_KEY` or `secret_key.txt` (important if public) |

---

## üß∞ Prerequisites & OS Notes

### Python

- Python 3.10+ recommended
- Install dependencies from [requirements.txt](requirements.txt)

### External services you may need

- **LLM provider** (OpenAI-compatible). Required for summaries.
- **Ollama** (optional): used when you choose local embeddings via [embedding_serve.sh](embedding_serve.sh).
- **MinerU** (optional):
  - API backend uses mineru.net and requires `MINERU_API_KEY`
  - local VLM backend uses `mineru-vllm-server` via [mineru_serve.sh](mineru_serve.sh)
- **LiteLLM** (optional): multi-model gateway configured by [llm.yml](llm.yml).

### Windows note

Some launchers are bash scripts ([up.sh](up.sh), [embedding_serve.sh](embedding_serve.sh), [mineru_serve.sh](mineru_serve.sh), [litellm.sh](litellm.sh)), and [run_services.py](run_services.py) invokes them with `bash`.

- On Windows, use **WSL** (recommended) or a bash-compatible environment.
- Alternatively, skip those services and run only the web app with `python serve.py` while using API backends for embeddings / MinerU.

## Configuration Guide

### Configuration Overview

| Source | Purpose | Required |
| --- | --- | --- |
| [vars.py](vars.py) | Core settings (paths, ports, LLM, email, MinerU, SVM) | ‚úÖ Yes |
| [arxiv_daemon.py](arxiv_daemon.py) | arXiv category lists for paper fetching | ‚öôÔ∏è Important |
| [llm.yml](llm.yml) | LiteLLM multi-model gateway | ‚öôÔ∏è Optional |
| Environment Variables | API keys, runtime toggles, scheduler params | ‚öôÔ∏è Recommended |
| [up.sh](up.sh) / [run_services.py](run_services.py) | Service startup parameters | ‚öôÔ∏è Optional |

**Files NOT in repository (.gitignore):**

- `vars.py` - Copy from [vars_template.py](vars_template.py)
- `llm.yml` - Copy from [llm_template.yml](llm_template.yml)
- `secret_key.txt` - Optional, for Flask session secret
- `data/` - Auto-generated at runtime (except `data/dict.db`)
- Local embedding models (e.g., `qwen3-embed-0.6B/`)

---

### 1. vars.py - Core Configuration

Copy `vars_template.py` to `vars.py` and configure the following sections:

#### 1.1 Data Storage

```python
DATA_DIR = "data"                              # Data storage root (SSD recommended)
SUMMARY_DIR = os.path.join(DATA_DIR, "summary") # Paper summaries cache
```

#### 1.2 Service Ports

```python
SERVE_PORT = 55555      # Web application port
EMBED_PORT = 51000      # Ollama embedding service port
MINERU_PORT = 52000     # MinerU VLM service port (vLLM)
LITELLM_PORT = 53000    # LiteLLM gateway port
```

#### 1.3 LLM API Configuration

```python
# Option 1: Direct API (OpenRouter, OpenAI, etc.)
LLM_BASE_URL = "https://openrouter.ai/api/v1"
LLM_API_KEY = os.environ.get("YOUR_LLM_API_KEY", "your_api_key")
LLM_NAME = "deepseek/deepseek-chat-v3.1:free"  # Model name
LLM_SUMMARY_LANG = "zh"                         # Summary language (zh/en)

# Option 2: Via LiteLLM gateway (requires llm.yml)
LLM_BASE_URL = f"http://localhost:{LITELLM_PORT}"
LLM_API_KEY = "no-key"  # LiteLLM handles auth
LLM_NAME = "or-mimo"    # Model alias defined in llm.yml
```

#### 1.4 Embedding Configuration

```python
# Use OpenAI-compatible API for embeddings (default)
EMBED_USE_LLM_API = True
EMBED_MODEL_NAME = "qwen3-embedding:0.6b"
EMBED_API_BASE = ""       # Empty = use LLM_BASE_URL
EMBED_API_KEY = ""        # Empty = use LLM_API_KEY

# Or use local Ollama service
EMBED_USE_LLM_API = False  # Uses http://localhost:{EMBED_PORT}
```

#### 1.5 Email Service

```python
from_email = "your_email@mail.com"
smtp_server = "smtp.mail.com"
smtp_port = 465                    # 25 for plain, 465 for SSL
email_username = "username"
email_passwd = os.environ.get("YOUR_EMAIL_PASSWD", "")
HOST = "http://your-server:55555"  # Public URL for email links
```

#### 1.6 Paper Summary Configuration

```python
SUMMARY_MIN_CHINESE_RATIO = 0.25          # Min Chinese ratio for cache validity
SUMMARY_DEFAULT_SEMANTIC_WEIGHT = 0.5     # Hybrid search weight (0.0-1.0)
SUMMARY_MARKDOWN_SOURCE = "html"          # "html" (default) or "mineru"
SUMMARY_HTML_SOURCES = "ar5iv,arxiv"      # HTML source priority order
```

#### 1.7 MinerU PDF Parsing

```python
MINERU_ENABLED = True                     # Enable/disable MinerU
MINERU_BACKEND = "api"                    # "api" (default), "pipeline", or "vlm-http-client"
MINERU_DEVICE = "cuda"                    # "cuda" (default) or "cpu" (pipeline backend only)
MINERU_MAX_WORKERS = 2                    # Concurrent minerU processes (pipeline only)
MINERU_MAX_VRAM = 3                       # Max VRAM per process in GB (pipeline+cuda only)
MINERU_API_KEY = os.environ.get("MINERU_API_KEY", "")  # For API backend
MINERU_API_POLL_INTERVAL = 5              # API polling interval in seconds
MINERU_API_TIMEOUT = 600                  # API task timeout in seconds
```

#### 1.8 SVM Recommendation Parameters

```python
SVM_C = 0.02          # C parameter for SVM classifier (regularization)
SVM_MAX_ITER = 5000   # Maximum iterations
SVM_TOL = 1e-3        # Tolerance
SVM_NEG_WEIGHT = 5.0  # Weight for explicit negative feedback samples
```

---

### 2. arxiv_daemon.py - arXiv Categories

The paper fetching query is built from `ALL_TAGS` in [arxiv_daemon.py](arxiv_daemon.py). Customize these groups to control which arXiv categories to fetch:

```python
# Default category groups (edit as needed)
CORE = ["cs.AI", "cs.LG", "stat.ML"]           # Core AI/ML
LANG = ["cs.CL", "cs.IR", "cs.CV"]             # NLP, IR, Computer Vision
AGENT = ["cs.MA", "cs.RO", "cs.HC", "cs.GT", "cs.NE"]  # Agents, Robotics, HCI
APP = ["cs.SE", "cs.CY"]                        # Software Engineering, Cybersecurity

ALL_TAGS = CORE + LANG + AGENT + APP
```

The query is constructed as `cat:cs.AI OR cat:cs.LG OR ...`. Add or remove categories based on your research interests.

**Common arXiv CS categories:**

- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language (NLP)
- `cs.CV` - Computer Vision
- `cs.RO` - Robotics
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Statistics Machine Learning

See [arXiv category taxonomy](https://arxiv.org/category_taxonomy) for the full list.

---

### 3. llm.yml - LiteLLM Gateway

Copy `llm_template.yml` to `llm.yml` if you want to use LiteLLM as a unified gateway for multiple LLM providers.

```yaml
model_list:
  # OpenRouter - Free models
  - model_name: or-mimo            # Alias used in vars.py LLM_NAME
    litellm_params:
      model: openrouter/xiaomi/mimo-v2-flash:free
      api_base: https://openrouter.ai/api/v1
      api_key: YOUR_OPENROUTER_API_KEY  # Replace with your key
      max_tokens: 32768

  - model_name: or-glm
    litellm_params:
      model: openai/z-ai/glm-4.5-air:free
      api_base: https://openrouter.ai/api/v1
      api_key: YOUR_OPENROUTER_API_KEY

litellm_settings:
  drop_params: true
```

**Usage:**

```bash
# Start LiteLLM gateway
litellm -c llm.yml --port 53000

# Or use run_services.py (auto-starts LiteLLM)
python3 run_services.py
```

Then configure `vars.py`:

```python
LLM_BASE_URL = f"http://localhost:{LITELLM_PORT}"
LLM_API_KEY = "no-key"
LLM_NAME = "or-mimo"  # Use alias from llm.yml
```

---

### 4. Environment Variables

#### Required

| Variable | Description | Example |
|----------|-------------|---------|
| `YOUR_LLM_API_KEY` | LLM provider API key | `sk-or-v1-...` |

#### Optional - API Keys

| Variable | Description | Example |
|----------|-------------|---------|
| `MINERU_API_KEY` | MinerU API key (for API backend PDF parsing) | `...` |
| `ARXIV_SANITY_MINERU_API_KEY` | MinerU API key alias (preferred by run_services.py) | `...` |
| `YOUR_EMAIL_PASSWD` | SMTP email password | `...` |
| `ARXIV_SANITY_SECRET_KEY` | Flask session secret (or use `secret_key.txt`) | `...` |
| `ARXIV_SANITY_EMBED_API_BASE` | Override embedding API base URL | `https://api.openai.com/v1` |
| `ARXIV_SANITY_EMBED_API_KEY` | Override embedding API key | `sk-...` |

#### Web & Runtime

| Variable | Default | Description |
|----------|---------|-------------|
| `ARXIV_SANITY_LOG_LEVEL` | `WARNING` | Log level: `DEBUG`, `INFO`, `WARNING`, `ERROR` |
| `ARXIV_SANITY_ACCESS_LOG` | `0` | Enable access logging (`1`/`0`) |
| `ARXIV_SANITY_RELOAD` | `0` | Development hot-reload mode |
| `ARXIV_SANITY_CACHE_PAPERS` | `1` | Cache full papers table in RAM (`1`/`0`) |
| `ARXIV_SANITY_WARMUP_DATA` | `1` | Background data cache warmup |
| `ARXIV_SANITY_WARMUP_ML` | `1` | Background ML model warmup |
| `ARXIV_SANITY_ENABLE_SCHEDULER` | `1` | Enable APScheduler cache refresh |
| `ARXIV_SANITY_ENABLE_CACHE_STATUS` | `0` | Enable `/cache_status` debug page |
| `ARXIV_SANITY_EMAIL_API_WORKERS` | `8` | Max parallel API calls when running [send_emails.py](send_emails.py) |

#### Web Security / Cookies

| Variable | Default | Description |
|----------|---------|-------------|
| `ARXIV_SANITY_COOKIE_SAMESITE` | `Lax` | Session cookie SameSite policy |
| `ARXIV_SANITY_COOKIE_SECURE` | `0` | Set secure cookies (requires HTTPS) |
| `ARXIV_SANITY_MAX_CONTENT_LENGTH` | `1048576` | Max request size in bytes (default 1 MiB) |

#### Summary Source

| Variable | Default | Description |
|----------|---------|-------------|
| `ARXIV_SANITY_SUMMARY_SOURCE` | `html` | Markdown source: `html` or `mineru` |
| `ARXIV_SANITY_HTML_SOURCES` | `ar5iv,arxiv` | HTML source priority order |

#### MinerU Backend

| Variable | Default | Description |
|----------|---------|-------------|
| `ARXIV_SANITY_MINERU_ENABLED` | `true` | Enable/disable MinerU |
| `ARXIV_SANITY_MINERU_BACKEND` | `api` | `api`, `pipeline`, or `vlm-http-client` |
| `ARXIV_SANITY_MINERU_DEVICE` | `cuda` | Device for pipeline backend |
| `ARXIV_SANITY_MINERU_MAX_WORKERS` | `2` | Max concurrent minerU processes |
| `ARXIV_SANITY_MINERU_MAX_VRAM` | `3` | Max VRAM per process (GB) |
| `MINERU_API_POLL_INTERVAL` | `5` | API polling interval (seconds) |
| `MINERU_API_TIMEOUT` | `600` | API task timeout (seconds) |

#### Locks & Concurrency

| Variable | Default | Description |
|----------|---------|-------------|
| `ARXIV_SANITY_SUMMARY_LOCK_STALE_SEC` | `600` | Stale timeout for summary cache locks (helps after crashes) |
| `ARXIV_SANITY_MINERU_LOCK_STALE_SEC` | `3600` | Stale timeout for MinerU parsing / GPU-slot locks |

#### Embedding

| Variable | Default | Description |
|----------|---------|-------------|
| `ARXIV_SANITY_EMBED_USE_LLM_API` | `true` | Use LLM API for embeddings |

#### Daemon/Scheduler

| Variable | Default | Description |
|----------|---------|-------------|
| `ARXIV_SANITY_FETCH_NUM` | `2000` | Papers to fetch per run |
| `ARXIV_SANITY_FETCH_MAX` | `1000` | Max results per API query |
| `ARXIV_SANITY_SUMMARY_NUM` | `200` | Papers to summarize per run |
| `ARXIV_SANITY_SUMMARY_WORKERS` | `2` | Summary worker threads |
| `ARXIV_SANITY_DAEMON_SUMMARY` | `1` | Enable summary generation in daemon |
| `ARXIV_SANITY_DAEMON_EMBEDDINGS` | `1` | Enable embeddings in daemon |
| `ARXIV_SANITY_PRIORITY_QUEUE` | `1` | Enable priority queue for summaries |
| `ARXIV_SANITY_PRIORITY_DAYS` | `2` | Priority window (days) |
| `ARXIV_SANITY_PRIORITY_LIMIT` | `100` | Max priority papers |
| `ARXIV_SANITY_ENABLE_GIT_BACKUP` | `1` | Enable git backup of dict.db |

#### Network / Proxy

- `http_proxy`, `https_proxy`: used by [arxiv_daemon.py](arxiv_daemon.py) and other outbound HTTP clients.

#### Gunicorn (up.sh)

| Variable | Default | Description |
|----------|---------|-------------|
| `GUNICORN_WORKERS` | `2` | Number of worker processes |
| `GUNICORN_THREADS` | `4` | Threads per worker |
| `ARXIV_SANITY_GUNICORN_PRELOAD` | `1` | Preload app in master process |
| `GUNICORN_EXTRA_ARGS` | `` | Additional gunicorn arguments |

---

### 5. Startup Parameters

#### run_services.py

```bash
# One-command start (recommended)
python3 run_services.py

# Web server options
python3 run_services.py --web gunicorn    # Use gunicorn
python3 run_services.py --web none        # Don't start web server

# Skip heavy services
python3 run_services.py --no-embed        # Skip Ollama embedding
python3 run_services.py --no-mineru       # Skip MinerU
python3 run_services.py --no-litellm      # Skip LiteLLM gateway

# Summary source
python3 run_services.py --summary-source html
python3 run_services.py --summary-source mineru

# Include scheduler daemon
python3 run_services.py --with-daemon

# One-shot: fetch and compute only
python3 run_services.py --fetch-compute         # Default 10000 papers
python3 run_services.py --fetch-compute 1000    # Custom count
```

#### arxiv_daemon.py

```bash
python3 arxiv_daemon.py -n 10000 -m 500    # Fetch up to 10000, 500 per query
python3 arxiv_daemon.py --init             # Initialize with keyword search
python3 arxiv_daemon.py --num-total 5000   # Limit total papers across categories
python3 arxiv_daemon.py --break-after 20   # Stop after 20 zero-new-paper batches
```

#### compute.py

```bash
python3 compute.py --num 20000             # TF-IDF features count
python3 compute.py --use_embeddings        # Enable embeddings (default)
python3 compute.py --no-embeddings         # Disable embeddings
python3 compute.py --embed_model nomic-embed-text  # Embedding model
python3 compute.py --embed_dim 512         # Embedding dimension
python3 compute.py --embed_batch_size 2048 # Batch size
```

#### batch_paper_summarizer.py

```bash
python3 batch_paper_summarizer.py -n 100 -w 2         # 100 papers, 2 workers
python3 batch_paper_summarizer.py --priority          # Priority queue mode
python3 batch_paper_summarizer.py --priority-days 2   # Priority window
python3 batch_paper_summarizer.py --dry-run           # Preview only
python3 batch_paper_summarizer.py -m "gpt-4o-mini"    # Specify model
```

---

## üöÄ Core Features

- **ü§ñ AI Paper Summarization**: Complete processing pipeline with HTML (arXiv/ar5iv) parsing or `minerU` PDF parsing, LLM summarization, and intelligent caching system
- **üîç Advanced Search Engine**: Keyword, semantic, and hybrid search modes with configurable weights and intelligent time filtering
- **üéØ Smart Recommendations**: Hybrid TF-IDF + embedding features with dynamic SVM classifiers trained on user preferences
- **üè∑Ô∏è Flexible Organization**: Personal tags with positive/negative feedback, combined tags, keyword tracking with AND/OR logic operations
- **üìö Reading List**: Personal paper collection with add/remove functionality, summary status tracking, and dedicated management page
- **üìß Email Intelligence**: Automated daily recommendations with personalized HTML templates and holiday-aware scheduling
- **‚ö° High Performance**: Multi-core processing, Intel extensions, incremental updates, Ollama embeddings + minerU(vLLM), and smart caching
- **üîó Modern Architecture**: RESTful APIs, responsive web interface, async summary loading, and comprehensive error handling
- **üîÑ Full Automation**: Built-in scheduler managing fetch‚Üícompute‚Üísummarize‚Üíemail pipeline with intelligent resource management

---

## üìñ Usage Guide

### User Interface Features

- **Account System (very lightweight)**:
  - Login is **username only** (no password). This is designed for personal / trusted deployments.
  - If you deploy on a public server, you should put it behind authentication (or VPN) and set a stable secret key.
- **Advanced Search**:
  - **Keyword Search**: Traditional text-based search with TF-IDF scoring
  - **Semantic Search**: AI-powered similarity search using embedding vectors
  - **Hybrid Search**: Combines keyword + semantic with adjustable weights (0.0-1.0)
  - **Tag-based**: SVM recommendations trained on your personal tags
  - **Time Filtering**: Smart filtering that preserves tagged papers even outside time window
- **Organization Tools**:
  - **Personal Tags**: Individual paper tagging with AND/OR logic
  - **Combined Tags**: Multi-tag categories (e.g., "RL,NLP") for complex topics
  - **Keywords**: Track specific terms across all papers
- **AI Paper Summaries**:
  - Click "Summary" for LLM-generated summaries
  - MathJax rendering for LaTeX formulas
  - Async loading with progress indicators
  - Cached for performance

### Daily Email Recommendations (optional)

1. Configure SMTP in [vars.py](vars.py) and set `YOUR_EMAIL_PASSWD` in environment.
2. Set `HOST` in [vars.py](vars.py) to the **public base URL** (used in email links).
3. In the website, go to Profile and set your email address.
4. Run [send_emails.py](send_emails.py) manually or run the scheduler [daemon.py](daemon.py).

If you have many users/tags, tune `ARXIV_SANITY_EMAIL_API_WORKERS` to limit concurrent API calls.

### Search Syntax

| Syntax | Example | Description |
|--------|---------|-------------|
| Field filters | `ti:transformer`, `au:goodfellow`, `cat:cs.LG` | Search specific fields |
| Phrases | `"diffusion model"` | Exact phrase match |
| Negation | `-survey`, `!survey` | Exclude terms |
| arXiv ID | `id:2312.12345` | Find by paper ID |

**Examples:**

- `ti:"graph neural network" cat:cs.LG` - Title contains phrase, category is cs.LG
- `au:goodfellow -survey` - Author is Goodfellow, exclude surveys
- `id:2312.12345` - Find specific paper

---

## ü§ñ AI Paper Summarization

### Complete AI Pipeline

1. **HTML/PDF Fetch**: Pull arXiv/ar5iv HTML (default) or PDFs with error handling
2. **Markdown Parsing**: HTML‚ÜíMarkdown (default) or minerU PDF parsing with structure recognition
3. **LLM Processing**: Generate comprehensive summaries using multiple OpenAI-compatible LLM providers
4. **Quality Control**: Chinese text ratio validation and content filtering
5. **Smart Caching**: Intelligent caching with automatic quality checks and storage optimization

### LLM Provider Examples

#### OpenRouter (Free Models)

```python
LLM_BASE_URL = "https://openrouter.ai/api/v1"
LLM_API_KEY = "sk-or-v1-..."
LLM_NAME = "deepseek/deepseek-chat-v3.1:free"
```

#### OpenAI

```python
LLM_BASE_URL = "https://api.openai.com/v1"
LLM_API_KEY = "sk-..."
LLM_NAME = "gpt-4o-mini"
```

### Summary Page Features

- **Clear Current Summary**: Removes only the summary for current model
- **Clear All**: Removes all caches for the paper (summaries, HTML, MinerU)

---

## üîß Advanced Features

### Embedding Models

```bash
# Pull and start embedding model (Ollama)
ollama pull nomic-embed-text
bash embedding_serve.sh  # Starts on EMBED_PORT

# Compute with embeddings
python3 compute.py --use_embeddings --embed_model nomic-embed-text
```

### Automated Scheduling

**Built-in Scheduler:**

```bash
python3 daemon.py
```

Schedule (Asia/Shanghai timezone):

- **Fetch+Compute**: Weekdays 8:00, 12:00, 16:00, 20:00
- **Send Emails**: Weekdays 18:00
- **Backup**: Daily 20:00

**Manual Cron:**

```cron
# Fetch and compute (weekdays 4x daily)
0 9,13,17,21 * * 1-5 cd /path && python3 arxiv_daemon.py -n 1000 && python3 compute.py --use_embeddings

# Send emails (weekdays 6 PM)
0 18 * * 1-5 cd /path && python3 send_emails.py -t 2

# Generate summaries (daily 7 PM)
0 19 * * * cd /path && python3 batch_paper_summarizer.py -n 200 -w 2
```

---

## üìö API Reference

### Search & Recommendations

- `GET /?rank=search&q=<query>` - Keyword search
- `GET /?rank=search&q=<query>&search_mode=semantic` - Semantic search
- `GET /?rank=search&q=<query>&search_mode=hybrid&semantic_weight=0.5` - Hybrid search
- `GET /?rank=tags&tags=<tag_list>&logic=<and|or>` - Tag-based SVM recommendations
- `GET /?rank=time&time_filter=<days>` - Time-filtered papers
- `GET /?rank=pid&pid=<paper_id>` - Similar papers

### Paper Summarization

- `GET /summary?pid=<paper_id>` - View summary page
- `POST /api/get_paper_summary` - Get summary JSON
- `POST /api/clear_model_summary` - Clear specific model's summary
- `POST /api/clear_paper_cache` - Clear all paper caches

### Tag & Keyword Management

- `GET /add/<pid>/<tag>` - Add tag to paper
- `GET /sub/<pid>/<tag>` - Remove tag from paper
- `GET /add_key/<keyword>` - Add tracking keyword
- `GET /del_key/<keyword>` - Remove tracking keyword

### System

- `GET /stats` - System statistics
- `GET /cache_status` - Cache status (authenticated users)

---

## üìà Changelog

### v3.1 - Reading List & Enhanced Tagging

- üìö **Reading List**: Personal paper collection with add/remove functionality and dedicated `/readinglist` page
- üëçüëé **Positive/Negative Tagging**: Enhanced feedback system with positive and negative tag states for SVM training
- ‚öñÔ∏è **SVM Negative Weight**: New `SVM_NEG_WEIGHT` config parameter for explicit negative feedback influence
- üîÑ **Real-time Sync**: BroadcastChannel-based state synchronization across browser tabs and components
- üìä **Summary Status**: Visual status indicators (queued/running/ok/failed) for summary generation
- üè∑Ô∏è **arXiv Tag Groups**: Grouped display of arXiv categories with dynamic About page updates
- üé® **UI Polish**: Enhanced tag dropdown interactions, confirmation dialogs, and visual feedback

### v3.0 - UI Redesign & HTML Summarization

- üé® **UI Overhaul**: Redesigned About, Profile, Stats pages with modern layout and feature grids
- üìÑ **HTML Summarization**: ar5iv/arxiv HTML parsing (faster than PDF, better structure)
- ü§ñ **Model Selection**: Multiple LLM models with auto-retry in summary page
- üîç **Enhanced Search**: Keyboard shortcuts (Ctrl+K), advanced filters, accessibility improvements
- üìä **Stats Chart**: Daily paper count visualization with bar chart
- üì¶ **LiteLLM Template**: `llm_template.yml` with OpenRouter free model configs

<details>
<summary>üìú Earlier Versions (v1.0 - v2.4)</summary>

### v2.4 - Multi-threading & Service Enhancement

- ‚ö° **Concurrency Optimization**: True multi-threaded concurrent paper summarization processing
- üîí **Thread Safety**: File-level locking mechanism to avoid minerU parsing conflicts
- üìä **Enhanced Statistics**: Detailed processing statistics and failure reason analysis
- üîÑ **Retry Mechanism**: Smart retry for failed paper processing tasks

### v2.3 - AI Paper Summarization

- ‚ú® **New**: Complete AI-powered paper summarization system
- üß† **MinerU Integration**: Advanced PDF parsing with structure recognition
- üìù **Summary Interface**: New `/summary` route with async loading

### v2.2 - Performance & Stability

- ‚ö° **Performance**: Enhanced unified data caching system with intelligent auto-reload
- üìà **Scheduler Enhancement**: Increased fetch frequency to 4x daily

### v2.1 - API & Semantic Search

- ‚ú® **New**: Semantic search with keyword, semantic, and hybrid modes
- üîó **API Integration**: RESTful API endpoints for recommendations

### v2.0 - Enhanced ML Features

- ‚ú® **New**: Hybrid TF-IDF + embedding vector features
- ‚ö° **Performance**: Multi-core optimization and Intel scikit-learn extensions

### v1.0 - Foundation

- üìö arXiv paper fetching and storage with SQLite database
- üè∑Ô∏è User tagging and keyword systems
- üìß Email recommendation service
- ü§ñ SVM-based paper recommendations

</details>

---

## üìù License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ‚≠ê Acknowledgments

- Original [arxiv-sanity-lite](https://github.com/karpathy/arxiv-sanity-lite) by Andrej Karpathy
- [minerU](https://github.com/opendatalab/MinerU) for advanced PDF parsing
- [Ollama](https://github.com/ollama/ollama) for local embedding serving
- [vLLM](https://github.com/vllm-project/vllm) for MinerU VLM serving
