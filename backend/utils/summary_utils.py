"""
Summary utilities for extracting TL;DR and other structured content from summary files.
"""

import re
from pathlib import Path
from typing import Optional

from loguru import logger

from config import settings

LLM_NAME = settings.llm.name
SUMMARY_DIR = str(settings.summary_dir)

# LaTeX to Unicode mapping for email display
LATEX_TO_UNICODE = {
    # Greek letters (lowercase)
    "alpha": "Î±",
    "beta": "Î²",
    "gamma": "Î³",
    "delta": "Î´",
    "epsilon": "Îµ",
    "varepsilon": "Ïµ",
    "zeta": "Î¶",
    "eta": "Î·",
    "theta": "Î¸",
    "vartheta": "Ï‘",
    "iota": "Î¹",
    "kappa": "Îº",
    "lambda": "Î»",
    "mu": "Î¼",
    "nu": "Î½",
    "xi": "Î¾",
    "pi": "Ï€",
    "varpi": "Ï–",
    "rho": "Ï",
    "varrho": "Ï±",
    "sigma": "Ïƒ",
    "varsigma": "Ï‚",
    "tau": "Ï„",
    "upsilon": "Ï…",
    "phi": "Ï†",
    "varphi": "Ï•",
    "chi": "Ï‡",
    "psi": "Ïˆ",
    "omega": "Ï‰",
    # Greek letters (uppercase)
    "Gamma": "Î“",
    "Delta": "Î”",
    "Theta": "Î˜",
    "Lambda": "Î›",
    "Xi": "Îž",
    "Pi": "Î ",
    "Sigma": "Î£",
    "Upsilon": "Î¥",
    "Phi": "Î¦",
    "Psi": "Î¨",
    "Omega": "Î©",
    # Math operators
    "cdot": "Â·",
    "cdots": "â‹¯",
    "ldots": "â€¦",
    "vdots": "â‹®",
    "ddots": "â‹±",
    "times": "Ã—",
    "div": "Ã·",
    "ast": "âˆ—",
    "star": "â˜…",
    "circ": "âˆ˜",
    "bullet": "â€¢",
    "oplus": "âŠ•",
    "otimes": "âŠ—",
    "ominus": "âŠ–",
    "odot": "âŠ™",
    "cap": "âˆ©",
    "cup": "âˆª",
    "wedge": "âˆ§",
    "vee": "âˆ¨",
    "land": "âˆ§",
    "lor": "âˆ¨",
    "bigwedge": "â‹€",
    "bigvee": "â‹",
    "bigcap": "â‹‚",
    "bigcup": "â‹ƒ",
    "pm": "Â±",
    "mp": "âˆ“",
    "setminus": "âˆ–",
    "propto": "âˆ",
    "sim": "âˆ¼",
    "simeq": "â‰ƒ",
    "approx": "â‰ˆ",
    "cong": "â‰…",
    "equiv": "â‰¡",
    "perp": "âŸ‚",
    "parallel": "âˆ¥",
    "mid": "âˆ£",
    # Text-style operators
    "log": "log",
    "ln": "ln",
    "exp": "exp",
    "sin": "sin",
    "cos": "cos",
    "tan": "tan",
    "max": "max",
    "min": "min",
    "sup": "sup",
    "inf": "inf",
    "arg": "arg",
    "dim": "dim",
    "det": "det",
    "Pr": "Pr",
    "argmax": "argmax",
    "argmin": "argmin",
    # Relation symbols
    "leq": "â‰¤",
    "le": "â‰¤",
    "geq": "â‰¥",
    "ge": "â‰¥",
    "neq": "â‰ ",
    "ne": "â‰ ",
    "ll": "â‰ª",
    "gg": "â‰«",
    "subset": "âŠ‚",
    "supset": "âŠƒ",
    "subseteq": "âŠ†",
    "supseteq": "âŠ‡",
    "in": "âˆˆ",
    "ni": "âˆ‹",
    "notin": "âˆ‰",
    "models": "âŠ¨",
    "vdash": "âŠ¢",
    # Set and logic symbols
    "emptyset": "âˆ…",
    "varnothing": "âˆ…",
    "forall": "âˆ€",
    "exists": "âˆƒ",
    "nexists": "âˆ„",
    "top": "âŠ¤",
    "bot": "âŠ¥",
    "Re": "â„œ",
    "Im": "â„‘",
    "aleph": "â„µ",
    # Arrow symbols
    "to": "â†’",
    "rightarrow": "â†’",
    "leftarrow": "â†",
    "leftrightarrow": "â†”",
    "Rightarrow": "â‡’",
    "Leftarrow": "â‡",
    "Leftrightarrow": "â‡”",
    "mapsto": "â†¦",
    "longrightarrow": "âŸ¶",
    "longleftarrow": "âŸµ",
    "Longrightarrow": "âŸ¹",
    "Longleftarrow": "âŸ¸",
    "hookrightarrow": "â†ª",
    "hookleftarrow": "â†©",
    "uparrow": "â†‘",
    "downarrow": "â†“",
    "implies": "â‡’",
    "impliedby": "â‡",
    "iff": "â‡”",
    # Common math symbols
    "infty": "âˆž",
    "infinity": "âˆž",
    "partial": "âˆ‚",
    "nabla": "âˆ‡",
    "angle": "âˆ ",
    "triangle": "â–³",
    "square": "â–¡",
    "diamond": "â—‡",
    "prime": "â€²",
    "dagger": "â€ ",
    "ddagger": "â€¡",
    "ell": "â„“",
    "hbar": "â„",
    # Calculus & operators
    "int": "âˆ«",
    "iint": "âˆ¬",
    "iiint": "âˆ­",
    "oint": "âˆ®",
    "sum": "âˆ‘",
    "prod": "âˆ",
    "coprod": "âˆ",
    "lim": "lim",
    "limsup": "lim sup",
    "liminf": "lim inf",
    "grad": "âˆ‡",
    # Font commands for common sets
    "mathbb{R}": "â„",
    "mathbb{N}": "â„•",
    "mathbb{Z}": "â„¤",
    "mathbb{Q}": "â„š",
    "mathbb{C}": "â„‚",
    "mathbb{E}": "ð”¼",
    "mathbb{P}": "â„™",
    "mathcal{F}": "â„±",
    "mathcal{L}": "â„’",
    "mathcal{O}": "ð’ª",
    "mathcal{H}": "â„‹",
    # Brackets and delimiters
    "langle": "âŸ¨",
    "rangle": "âŸ©",
    "lceil": "âŒˆ",
    "rceil": "âŒ‰",
    "lfloor": "âŒŠ",
    "rfloor": "âŒ‹",
    "left": "",
    "right": "",
    "big": "",
    "Big": "",
    "bigg": "",
    "Bigg": "",
    # Spacing commands
    ",": " ",
    ";": " ",
    "quad": " ",
    "qquad": "  ",
    " ": " ",
    # Text-style commands (strip)
    "text": "",
    "mathrm": "",
    "mathbf": "",
    "mathit": "",
    "mathsf": "",
    "mathtt": "",
    "textbf": "",
    "textit": "",
    "emph": "",
    "bm": "",
    "boldsymbol": "",
    # Accents
    "hat": "^",
    "widehat": "^",
    "bar": "Â¯",
    "overline": "Â¯",
    "tilde": "~",
    "widetilde": "~",
    "vec": "â†’",
    "dot": "Ë™",
    "ddot": "Â¨",
    # Misc
    "colon": ":",
    "dots": "â€¦",
}

# Superscript mapping for common characters
_SUPERSCRIPT_MAP = {
    "0": "â°",
    "1": "Â¹",
    "2": "Â²",
    "3": "Â³",
    "4": "â´",
    "5": "âµ",
    "6": "â¶",
    "7": "â·",
    "8": "â¸",
    "9": "â¹",
    "+": "âº",
    "-": "â»",
    "=": "â¼",
    "(": "â½",
    ")": "â¾",
    "n": "â¿",
    "i": "â±",
    "T": "áµ€",
}

# Subscript mapping for common characters
_SUBSCRIPT_MAP = {
    "0": "â‚€",
    "1": "â‚",
    "2": "â‚‚",
    "3": "â‚ƒ",
    "4": "â‚„",
    "5": "â‚…",
    "6": "â‚†",
    "7": "â‚‡",
    "8": "â‚ˆ",
    "9": "â‚‰",
    "+": "â‚Š",
    "-": "â‚‹",
    "=": "â‚Œ",
    "(": "â‚",
    ")": "â‚Ž",
    "a": "â‚",
    "e": "â‚‘",
    "i": "áµ¢",
    "j": "â±¼",
    "k": "â‚–",
    "n": "â‚™",
    "o": "â‚’",
    "p": "â‚š",
    "r": "áµ£",
    "s": "â‚›",
    "t": "â‚œ",
    "u": "áµ¤",
    "v": "áµ¥",
    "x": "â‚“",
}


def _convert_script(text: str, mapping: dict) -> str:
    """Convert text to super/subscript using Unicode mapping."""
    result = []
    for ch in text:
        result.append(mapping.get(ch, ch))
    return "".join(result)


def latex_to_plaintext(text: str) -> str:
    """
    Convert LaTeX math notation to readable Unicode plaintext for email display.

    Args:
        text: Text containing LaTeX math notation (with $ delimiters)

    Returns:
        Plaintext with LaTeX converted to Unicode symbols
    """
    if not text:
        return ""

    result = text

    # Handle \frac{a}{b} -> (a)/(b)
    frac_pattern = re.compile(r"\\(?:d|t)?frac\s*\{([^{}]*(?:\{[^{}]*\}[^{}]*)*)\}\s*\{([^{}]*(?:\{[^{}]*\}[^{}]*)*)\}")
    while frac_pattern.search(result):
        result = frac_pattern.sub(r"(\1)/(\2)", result)

    # Handle \sqrt{x} -> âˆš(x)
    sqrt_pattern = re.compile(r"\\sqrt\s*\{([^{}]*(?:\{[^{}]*\}[^{}]*)*)\}")
    result = sqrt_pattern.sub(r"âˆš(\1)", result)

    # Handle \sqrt[n]{x} -> â¿âˆš(x)
    sqrt_n_pattern = re.compile(r"\\sqrt\s*\[([^\]]+)\]\s*\{([^{}]*)\}")
    result = sqrt_n_pattern.sub(r"\1âˆš(\2)", result)

    # Handle font commands with braces: \mathbb{R} etc. (check dict first)
    font_cmds = [
        "mathbb",
        "mathcal",
        "mathbf",
        "mathrm",
        "mathit",
        "mathsf",
        "text",
        "textbf",
        "textit",
        "bm",
        "boldsymbol",
    ]
    for cmd in font_cmds:
        pattern = re.compile(r"\\" + cmd + r"\s*\{([^{}]*)\}")

        def replace_font(m, cmd=cmd):
            full_key = cmd + "{" + m.group(1) + "}"
            if full_key in LATEX_TO_UNICODE:
                return LATEX_TO_UNICODE[full_key]
            # Just return the content without the command
            return m.group(1)

        result = pattern.sub(replace_font, result)

    # Handle superscripts: x^{abc} or x^2
    def replace_superscript(m):
        content = m.group(1) if m.group(1) else m.group(2)
        # Try to convert all characters, fall back to ^(...) if not possible
        converted = _convert_script(content, _SUPERSCRIPT_MAP)
        if converted != content or all(c in _SUPERSCRIPT_MAP for c in content):
            return converted
        return f"^{content}" if len(content) == 1 else f"^({content})"

    result = re.sub(r"\^(?:\{([^{}]+)\}|(\w))", replace_superscript, result)

    # Handle subscripts: x_{abc} or x_2
    def replace_subscript(m):
        content = m.group(1) if m.group(1) else m.group(2)
        converted = _convert_script(content, _SUBSCRIPT_MAP)
        if converted != content or all(c in _SUBSCRIPT_MAP for c in content):
            return converted
        return f"_{content}" if len(content) == 1 else f"_({content})"

    result = re.sub(r"_(?:\{([^{}]+)\}|(\w))", replace_subscript, result)

    # Replace LaTeX commands from dictionary (longest match first)
    sorted_keys = sorted(LATEX_TO_UNICODE.keys(), key=len, reverse=True)
    for cmd in sorted_keys:
        # Skip font commands already handled
        if any(cmd.startswith(f + "{") for f in font_cmds):
            continue
        # Escape special regex characters in the command
        escaped = re.escape(cmd)
        # Match \cmd followed by word boundary or non-letter
        pattern = rf"\\{escaped}(?![a-zA-Z])"
        result = re.sub(pattern, LATEX_TO_UNICODE[cmd], result)

    # Remove remaining unknown \commands (keep content)
    result = re.sub(r"\\([a-zA-Z]+)", r"\1", result)

    # Remove $ delimiters (both inline $...$ and display $$...$$)
    result = re.sub(r"\$\$([^$]+)\$\$", r" \1 ", result)
    result = re.sub(r"\$([^$]+)\$", r"\1", result)

    # Also handle \( \) and \[ \] delimiters
    result = re.sub(r"\\\(([^)]+)\\\)", r"\1", result)
    result = re.sub(r"\\\[([^\]]+)\\\]", r" \1 ", result)

    # Clean up extra whitespace
    result = re.sub(r"[ \t]+", " ", result)
    result = result.strip()

    return result


def markdown_to_email_html(text: str) -> str:
    """
    Convert markdown formatting to HTML for email display.
    Handles bold, italic, links, lists, and converts LaTeX to plaintext.

    Args:
        text: Text with markdown formatting and LaTeX

    Returns:
        HTML-safe text with formatting preserved
    """
    if not text:
        return ""

    # First convert LaTeX to plaintext
    result = latex_to_plaintext(text)

    # Process line-by-line for block elements
    lines = result.split("\n")
    processed_lines = []
    i = 0

    while i < len(lines):
        line = lines[i]

        # Horizontal rule: ---, ***, ___
        if re.match(r"^\s*[-*_]{3,}\s*$", line):
            processed_lines.append("<hr>")
            i += 1
            continue

        # Headings: # Title -> <strong>Title</strong>
        heading_match = re.match(r"^(#{1,6})\s+(.+)$", line)
        if heading_match:
            content = heading_match.group(2)
            processed_lines.append(f"<strong>{content}</strong>")
            i += 1
            continue

        # Blockquote: > text
        if line.startswith(">"):
            quote_lines = []
            while i < len(lines) and lines[i].startswith(">"):
                quote_content = re.sub(r"^>\s?", "", lines[i])
                quote_lines.append(quote_content)
                i += 1
            processed_lines.append(f"<blockquote>{'<br>'.join(quote_lines)}</blockquote>")
            continue

        # Unordered list: - item, * item, + item
        if re.match(r"^\s*[-*+]\s+", line):
            list_items = []
            while i < len(lines) and re.match(r"^\s*[-*+]\s+", lines[i]):
                item_content = re.sub(r"^\s*[-*+]\s+", "", lines[i])
                list_items.append(f"<li>{item_content}</li>")
                i += 1
            processed_lines.append(f"<ul>{''.join(list_items)}</ul>")
            continue

        # Ordered list: 1. item, 2. item
        if re.match(r"^\s*\d+\.\s+", line):
            list_items = []
            while i < len(lines) and re.match(r"^\s*\d+\.\s+", lines[i]):
                item_content = re.sub(r"^\s*\d+\.\s+", "", lines[i])
                list_items.append(f"<li>{item_content}</li>")
                i += 1
            processed_lines.append(f"<ol>{''.join(list_items)}</ol>")
            continue

        # Regular line
        processed_lines.append(line)
        i += 1

    result = "\n".join(processed_lines)

    # Inline formatting (applied after block processing)

    # Links: [text](url) -> <a href="url">text</a>
    result = re.sub(
        r"\[([^\]]+)\]\((https?://[^)\s]+)\)",
        r'<a href="\2">\1</a>',
        result,
    )

    # Images: ![alt](url) -> link fallback for email
    result = re.sub(
        r"!\[([^\]]*)\]\((https?://[^)\s]+)\)",
        r'<a href="\2">[image: \1]</a>',
        result,
    )

    # Strikethrough: ~~text~~ -> <del>text</del>
    result = re.sub(r"~~([^~]+)~~", r"<del>\1</del>", result)

    # Bold: **text** or __text__ -> <strong>text</strong>
    result = re.sub(r"\*\*([^*]+)\*\*", r"<strong>\1</strong>", result)
    result = re.sub(r"__([^_]+)__", r"<strong>\1</strong>", result)

    # Italic: *text* or _text_ -> <em>text</em>
    result = re.sub(r"(?<![*])\*([^*]+)\*(?![*])", r"<em>\1</em>", result)
    result = re.sub(r"(?<![_\w])_([^_]+)_(?![_\w])", r"<em>\1</em>", result)

    # Inline code: `code` -> <code>code</code>
    result = re.sub(r"`([^`]+)`", r"<code>\1</code>", result)

    # Convert remaining newlines to <br> for email
    result = result.replace("\n", "<br>")

    return result


# Pre-compiled regex patterns for TL;DR extraction
# Block pattern: TL;DR as a heading with content on following lines
_TLDR_BLOCK_PATTERN = re.compile(
    r"(?:^|\n)(?:>?\s*)?(?:#{1,6}\s*|\*{1,2})?TL;DR(?:\*{1,2})?:?\s*\n+(.*?)(?=\n#{1,6}\s+\S|\n\*{2}[^*]+\*{2}|\Z)",
    re.IGNORECASE | re.DOTALL,
)

# Inline pattern: TL;DR with content on the same line
_TLDR_INLINE_PATTERN = re.compile(
    r"(?:^|\n)(?:>?\s*)?(?:#{1,6}\s*|\*{1,2})?TL;DR(?:\*{1,2})?:?\s*(.+)$",
    re.IGNORECASE | re.MULTILINE,
)


def get_summary_file(pid: str, preferred_model: Optional[str] = None) -> Optional[Path]:
    """
    Find the summary file for a given paper ID.

    Args:
        pid: Paper ID (may include version like "2301.00001v2")

    Returns:
        Path to the summary file if found, None otherwise
    """
    raw_pid = pid.split("v")[0] if "v" in pid else pid

    # Try new layered structure first: SUMMARY_DIR/{pid}/{model}.md
    summary_dir = Path(SUMMARY_DIR) / raw_pid

    if summary_dir.exists() and summary_dir.is_dir():
        # Prefer the configured default model (vars.LLM_NAME) unless overridden.
        preferred = (preferred_model or LLM_NAME or "").strip()
        if preferred:
            preferred_path = summary_dir / f"{preferred}.md"
            if preferred_path.is_file():
                return preferred_path

        # Fallback: find any .md file (sorted for stability)
        md_files = sorted(summary_dir.glob("*.md"))
        if md_files:
            return md_files[0]

    # Try legacy flat structure: SUMMARY_DIR/{pid}.md
    legacy_file = Path(SUMMARY_DIR) / f"{raw_pid}.md"
    if legacy_file.exists():
        return legacy_file

    return None


def extract_tldr_from_content(content: str, max_length: int = 500) -> str:
    """
    Extract TL;DR from summary content.

    Args:
        content: Summary markdown content
        max_length: Maximum length of TL;DR text

    Returns:
        TL;DR text, or empty string if not found
    """
    if not content:
        return ""

    # Try block pattern first (TL;DR as heading with content on following lines)
    match = _TLDR_BLOCK_PATTERN.search(content)

    # If not found, try inline pattern (TL;DR with content on same line)
    if not match:
        match = _TLDR_INLINE_PATTERN.search(content)

    if not match:
        return ""

    tldr = match.group(1).strip()

    # Clean up blockquote markers if present
    tldr = re.sub(r"^>\s?", "", tldr, flags=re.MULTILINE).strip()

    # Take first paragraph only
    first_para = tldr.split("\n\n")[0].strip()

    # Truncate if too long
    if len(first_para) > max_length:
        first_para = first_para[: max_length - 3] + "..."

    return first_para


def read_tldr_from_summary_file(pid: str) -> str:
    """
    Read and extract TL;DR from the summary file for a given paper.

    Args:
        pid: Paper ID

    Returns:
        TL;DR content string, or empty string if not found
    """
    summary_file = get_summary_file(pid)

    if not summary_file:
        return ""

    try:
        content = summary_file.read_text(encoding="utf-8")
        return extract_tldr_from_content(content)
    except Exception as e:
        logger.debug(f"Failed to extract TL;DR for {pid}: {e}")
        return ""
